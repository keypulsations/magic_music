1. accept video file [✓]
2. gather scene change onset_times into newfile [✓]
3. pass onset_times file to supercollider as argument [✓]
4. split those onset times into an array [✓]

5. use those onset times to approximate best beat using suggestions by Nathan Ho and Dan Zink [WIP]
---write back both Nathan Ho and Dan Zink, and Michael Casey
---are the beats they suggest actually the best?

6. mutate video speed around approximate beat
---v1, simply change speed of each chunk so that it matches

7. create music around video, generating melodies with magenta [WIP]
---limitations:
-----timbres (drum/bass/pad/lead)
-----handful of melodic variations generated
-----tempo/beat (determined by video content)
---fade in the melody, first just parts of it, ultimately the whole thing, with variations
---use silence...bring drums in and out

8. play video simultaneously with music [✓]

9. web interface to drop video (must be between 1m/2m), show analysis and playback (study jukedeck, amper)
10. stripe form to buy
---lossess audio track
---combined video with music (without video's original sound)
---mix of video with music and original audio

### idea to pursue: drum drops exactly with last scene change because of "if(i<~durations.size) {" in magic_music.scd
### ...use this approach to leave beats/melodies out, bring them back in, etc.

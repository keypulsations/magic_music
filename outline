1. accept video file [✓]
2. gather scene change onset_times into newfile [✓]
3. pass onset_times file to supercollider as argument [✓]
4. split those onset times into an array [✓]

5. use those onset times to approximate best beat using suggestions by Nathan Ho and Dan Zink [WIP]
---write back both Nathan Ho and Dan Zink, and Michael Casey
---are the beats they suggest actually the best?

6. mutate video speed around approximate beat
---v1, simply change speed of each segment so that it matches
---have video play to the end (currently missing last segment)
---drop drums intermittently with `durations.size` in magic_music.scd

7. create music around video, generating melodies with magenta [WIP]
---limitations:
-----timbres (drum/bass/pad/lead)
-----handful of melodic variations generated
-----tempo/beat (determined by video content)
---fade in the melody, first just parts of it, ultimately the whole thing, with variations
---use silence...bring drums in and out

8. play video simultaneously with music [✓]

9. web interface to drop video (must be between 1m/2m), show analysis and playback (study jukedeck, amper)
10. stripe form to buy
---lossess audio track
---combined video with music (without video's original sound)
---mix of video with music and original audio

***
gen onsets from mezzanine vid (bash/ffmpeg)
use onsets to find mainbeat (sc)
use mainbeat to quantize video (pass onsets, mainbeat and filename to rb)
regenerate onsets (???)
generate music to play with quantized vid (sc with new video)
